{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buthaina279/P4DS/blob/main/COMP5623M_CW2v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR4bovYL4CJz"
      },
      "source": [
        "## OCOM5203M Practical Assignment 2 - Image Caption Generation [100 marks]\n",
        "\n",
        "The maximum number of marks for each part are shown in the section headers. As indicated in the main heading above, the overall assessment carries a maximum of 100 marks.\n",
        "\n",
        "This summative assessment is weighted 25% of the final grade for the module.\n",
        "\n",
        "### Motivation \n",
        "\n",
        "Through this coursework, you will:\n",
        "\n",
        "> 1. Understand the principles of text pre-processing and vocabulary building.\n",
        "> 2. Gain experience working with an image to text model.\n",
        "> 3. Use and compare two different text similarity metrics for evaluating an image to text model, and understand evaluation challenges.\n",
        "\n",
        "\n",
        "### Setup and resources \n",
        "\n",
        "Having a GPU will speed up the image feature extraction process. If you would like to use a GPU, please refer to the module website for recommended working environments with GPUs.\n",
        "\n",
        "Please implement the coursework using Python and PyTorch, and refer to the notebooks and exercises provided.\n",
        "\n",
        "This coursework will use a subset of the [COCO \"Common Objects in Context\" dataset](https://cocodataset.org/) for image caption generation. COCO contains 330K images, of 80 object categories, and at least five textual reference captions per image. Our subset consists of 5029 of these images, each of which has five or more different descriptions of the salient entities and activities, and we will refer to it as COCO_5029.\n",
        "\n",
        "To download the data:\n",
        "\n",
        "> 1. **Images**: download the zip file \"coco_subset_images.zip (812MB)\" [here](https://leeds365-my.sharepoint.com/:f:/g/personal/scsrss_leeds_ac_uk/EnVzgHGd-fhIhTcnxdK5hawBpGQz9isq8Bo8-Xhlwf6uwQ?e=e3LEru).\n",
        "> 2. **Reference captions**: on the COCO [download page](https://cocodataset.org/#download), download the file named \"2017 Train/Val annotations (241MB)\". \n",
        "> 3. **Image meta data**: as our set is a subset of full COCO dataset, we have created a CSV file containing relevant meta data for our particular subset of images. You can download it also from Drive, \"coco_subset_meta.csv\" at the same link as 1.\n",
        "\n",
        "\n",
        "### Submission\n",
        "\n",
        "Please submit the following:\n",
        "\n",
        "> 1. Your completed Jupyter notebook file, in .ipynb format. **Do not change the file name or the automatic grading will be affected.**\n",
        "> 2. The .html version of your notebook; File > Download as > HTML (.html). Check that all cells have been run and all outputs (including all graphs you would like to be marked) displayed in the .html for marking.\n",
        "\n",
        "\n",
        "Final note:\n",
        "\n",
        "> **Please include in this notebook everything that you would like to be marked, including figures. Under each section, put the relevant code containing your solution. You may re-use functions you defined previously, but any new code must be in the relevant section.** Feel free to add as many code cells as you need under each section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYiJoB1DGsBu"
      },
      "source": [
        "Your student username:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-noUW2RGsBx"
      },
      "outputs": [],
      "source": [
        "ml20baya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKuHJwUHGsBz"
      },
      "source": [
        "Your full name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiraFLqAGsB2"
      },
      "outputs": [],
      "source": [
        "Buthaina Abdullah Alshareef"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suMfo95fGsB3"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Feel free to add to this section as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "0kEDNBUnGsB4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms,utils\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZvPCpQmGsB7"
      },
      "source": [
        "Detect which device (CPU/GPU) to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGxv1PyYGsB8",
        "outputId": "1d103f20-2726-4188-ea83-573ca82c26fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqB4AQ5hGsB9"
      },
      "source": [
        "The basic principle of our image-to-text model is as pictured in the diagram below, where an Encoder network encodes the input image as a feature vector by providing the outputs of the last fully-connected layer of a pre-trained CNN (we use [ResNet-152](https://arxiv.org/abs/1512.03385)). This pretrained network has been trained on the complete ImageNet dataset and is thus able to recognise common objects. \n",
        "\n",
        "These features are then fed into a Decoder network along with the reference captions. As the image feature dimensions are large and sparse, the Decoder network includes a linear layer which downsizes them, followed by a batch normalisation layer to speed up training. Those resulting features, as well as the reference text captions, are passed into a recurrent network (we will use an RNN). \n",
        "\n",
        "The reference captions used to compute loss are represented as numerical vectors via an embedding layer whose weights are learned during training.\n",
        "\n",
        "![Encoder Decoder](encoder_decoder_diagramv2022.png)\n",
        "\n",
        "The Encoder-Decoder network could be coupled and trained end-to-end, without saving features to disk; however, this requires iterating through the entire image training set during training. We can make the training more efficient by decoupling the networks. \n",
        "\n",
        "We will first extract the feature representations of the images from the Encoder and save them (Part 1). During training of the Decoder (Part 3), we only need to iterate over the image feature data and the reference captions.\n",
        "\n",
        "### Overview\n",
        "\n",
        "> 1. Extracting image features \n",
        "> 2. Text preparation of training and validation data \n",
        "> 3. Training the decoder\n",
        "> 4. Generating predictions on test data\n",
        "> 5. Caption evaluation via BLEU score\n",
        "> 6. Caption evaluation via Cosine similarity\n",
        "> 7. Comparing BLEU and Cosine similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DxtzO8VGsB-"
      },
      "source": [
        "## 1 Extracting image features [11 marks]\n",
        "\n",
        "### 1.1 EncoderCNN\n",
        "\n",
        "Read through the template EncoderCNN class below and complete the class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZIrtWIRTFVX",
        "outputId": "9886513e-22c1-4f66-ae95-6767eb2ef2d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oUYXujhLSD6w"
      },
      "outputs": [],
      "source": [
        "#for google drive\n",
        "ROOT = \"/content/drive/MyDrive/CW2_AI/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ8ewgIpteMz"
      },
      "outputs": [],
      "source": [
        "#for laptop\n",
        "ROOT = \"/Users/macbookpro/Google Drive/CW2_AI/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eyIF0_13GsB_"
      },
      "outputs": [],
      "source": [
        "class EncoderCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"Load the pretrained ResNet-152 and replace top fc layer.\"\"\"\n",
        "        super(EncoderCNN, self).__init__()\n",
        "        resnet = models.resnet152(pretrained=True)\n",
        "\n",
        "        # TO COMPLETE\n",
        "        # keep all layers of the pretrained net except the last one\n",
        "        self.resnet_d = torch.nn.Sequential(*(list(resnet.children())[:-1]))\n",
        "\n",
        "        \n",
        "    def forward(self, images):\n",
        "        \"\"\"Extract feature vectors from input images.\"\"\"\n",
        "        #print(\"image\", images.shape)\n",
        "        # [64, 3, 128, 128]\n",
        "        # pass the batch of images (images) to self.resnet_d\n",
        "        with torch.no_grad():\n",
        "          features = self.resnet_d(images)\n",
        "\n",
        "        #print(\"before\", features.shape)\n",
        "        features = features.reshape(features.size(0), -1)\n",
        "        \n",
        "        #print(\"after\", features.shape)\n",
        "        #print(len(outputs))\n",
        "        # shape you want is [batch_size, feature_dims] for example, [64, 2048]\n",
        "\n",
        "        # TO COMPLETE\n",
        "        # remember no gradients are needed\n",
        "        return features \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9kRP7Q8GsCC",
        "outputId": "9d5782f5-6d79-4b25-aa5f-5ae57540c115"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderCNN(\n",
              "  (resnet_d): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (8): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (9): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (10): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (11): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (12): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (13): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (14): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (15): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (16): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (17): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (18): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (19): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (20): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (21): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (22): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (23): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (24): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (25): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (26): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (27): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (28): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (29): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (30): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (31): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (32): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (33): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (34): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (35): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# instantiate encoder and put into evaluation mode.\n",
        "encoder = EncoderCNN().to(device)\n",
        "encoder.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf7QaXytGsCE"
      },
      "source": [
        "### 1.2 Processing the images\n",
        "\n",
        "Pass the images through the ```Encoder``` model, saving the resulting features for each image. You may like to use a ```Dataset``` and ```DataLoader``` to load the data in batches for faster processing, or you may choose to simply read in one image at a time from disk without any loaders.\n",
        "\n",
        "Note that as this is a forward pass only, no gradients are needed. You will need to be able to match each image ID (the image name without file extension) with its features later, so we suggest either saving a dictionary of image ID: image features, or keeping a separate ordered list of image IDs.\n",
        "\n",
        "Use this ImageNet transform provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejoxuOnvGsCG"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([ \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(224), \n",
        "    transforms.CenterCrop(224), \n",
        "    transforms.Normalize((0.485, 0.456, 0.406),   # using ImageNet norms\n",
        "                         (0.229, 0.224, 0.225))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JN13xW7aGsCJ"
      },
      "outputs": [],
      "source": [
        "class COCO(Dataset):\n",
        "    def __init__(self, df, transform = None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.df['path'][index])\n",
        "        file_loc = self.df['path'][index]\n",
        "        file_name = file_loc.split('/')[-1]\n",
        "        \n",
        "        try:\n",
        "            img = img.convert('RGB')\n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, file_name.replace('.jpg','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmxLmwu9GsCK",
        "outputId": "614eaa72-42a8-45f9-cd2c-403cf64e5db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of coco images =  5029 image\n",
            "                                                path\n",
            "0  /content/drive/MyDrive/CW2_AI/images/000000516...\n",
            "1  /content/drive/MyDrive/CW2_AI/images/000000540...\n",
            "2  /content/drive/MyDrive/CW2_AI/images/000000368...\n",
            "3  /content/drive/MyDrive/CW2_AI/images/000000205...\n",
            "4  /content/drive/MyDrive/CW2_AI/images/000000229...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "coco_dir = ROOT + \"images\"\n",
        "img_paths= []\n",
        "img_name= []\n",
        "\n",
        "for entry in os.scandir(coco_dir):\n",
        "    if (entry.is_file()):\n",
        "        img_paths.append(entry.path)\n",
        "        img_name.append(entry.name)\n",
        "\n",
        "\n",
        "\n",
        "data = {'path': img_paths}\n",
        "\n",
        "coco_df = pd.DataFrame(data, columns=['path'])\n",
        "\n",
        "\n",
        "print(\"length of coco images = \", len(coco_df), \"image\")\n",
        "print(coco_df.head())\n",
        "\n",
        "coco_dataset = COCO(\n",
        "    \n",
        "    df=coco_df,\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "coco_loader = DataLoader(\n",
        "    coco_dataset,\n",
        "    batch_size=15,\n",
        "    shuffle=False,\n",
        "    num_workers=6\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fsOL1tMPXqkY",
        "outputId": "b765c08b-60f4-45d8-fa90-849c262dad20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "000000516212\n"
          ]
        }
      ],
      "source": [
        "img, img_id = next(iter(coco_loader))\n",
        "xa = np.transpose(img[0].numpy(),(1,2,0))\n",
        "plt.imshow(xa)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "print(img_id[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLWVT3lnVUK2"
      },
      "outputs": [],
      "source": [
        "#save image name in a dictionary along with return features \n",
        "#dataiter = iter(coco_loader)\n",
        "#images, labels = dataiter.next()\n",
        "#torch.unsqueeze(images, 0)\n",
        "features = torch.tensor([])\n",
        "features = features.to(device)\n",
        "features_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in coco_loader:\n",
        "    inputs = data.to(device)\n",
        "    outputs = encoder(inputs)\n",
        "          #inputs= data\n",
        "       \n",
        "          #64, 2048\n",
        "          #tuple = (outputs)\n",
        "          #tt = outputs.data\n",
        "    features_batch = torch.cat((features,outputs), 0)\n",
        "    features_list.extend(features_batch.tolist())\n",
        "          #print(\"for loop\", features_batch.shape)\n",
        "    print(\"features_batch\",features_batch.shape)\n",
        "\n",
        "\n",
        "print(\"after all batches\",features_batch)\n",
        "print(\"length\", len(features_list))\n",
        "\n",
        "        # for id in img_name:\n",
        "        #   index_of_dot = id.index('.')\n",
        "        #   file_name_without_extension = id[:index_of_dot]\n",
        "\n",
        "\n",
        "        #   image_feature_dic = {'img_id': id,'feature_vector':outputs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ouMGomUxnty"
      },
      "outputs": [],
      "source": [
        "results_path = ROOT+'features.pt'\n",
        "torch.save(features_list, results_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "P2F3rHVj5fVq",
        "outputId": "a5a81b26-9fc0-4b00-b0bc-bab96bae7650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "features_tensors = []\n",
        "img_id_map = {}\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in coco_loader:\n",
        "    img, img_id = data\n",
        "    img = img.to(device)\n",
        "    features = encoder(img)\n",
        "\n",
        "    for img_id,feature in zip(img_id, features):\n",
        "      img_id_map[img_id] = feature\n",
        "      features_tensors.append(feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr-WUAwn6o76"
      },
      "outputs": [],
      "source": [
        "torch.save(features_tensors, ROOT+'features_tensors.pt')\n",
        "torch.save(img_id_map, ROOT+'imgid_features_map.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfR--uYXHdIi"
      },
      "source": [
        "## 2 Text preparation [23 marks]\n",
        "\n",
        "\n",
        "### 2.1 Build the caption dataset\n",
        "\n",
        "All our selected COCO_5029 images are from the official 2017 train set.\n",
        "\n",
        "The ```coco_subset_meta.csv``` file includes the image filenames and unique IDs of all the images in our subset. The ```id``` column corresponds to each unique image ID.\n",
        "\n",
        "The COCO dataset includes many different types of annotations: bounding boxes, keypoints, reference captions, and more. We are interested in the captioning labels. Open ```captions_train2017.json``` from the zip file downloaded from the COCO website. You are welcome to come up with your own way of doing it, but we recommend using the ```json``` package to initially inspect the data, then the ```pandas``` package to look at the annotations (if you read in the file as ```data```, then you can access the annotations dictionary as ```data['annotations']```).\n",
        "\n",
        "Use ```coco_subset_meta.csv``` to cross-reference with the annotations from ```captions_train2017.json``` to get all the reference captions for each image in COCO_5029.\n",
        "\n",
        "For example, you may end up with data looking like this (this is a ```pandas``` DataFrame, but it could also be several lists, or some other data structure/s):\n",
        "\n",
        "<img src=\"df_caption_set.png\" alt=\"images matched to caption\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9JQE-TlGsCN",
        "outputId": "9b5d32a9-1046-43b9-f67b-8b12d4de3d6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8000, 8)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read Meta data into dataframe\n",
        "\n",
        "coco_meta = pd.read_csv(ROOT + 'coco_subset_meta.csv', index_col=0) # remove unamed column\n",
        "\n",
        "coco_meta.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "CpX1I3lVJDUf",
        "outputId": "cc3666d6-2189-4398-d52c-0319ed144c0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-39f7aa41-3c19-46b5-b610-2d14f3b43bc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>license</th>\n",
              "      <th>file_name</th>\n",
              "      <th>coco_url</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>date_captured</th>\n",
              "      <th>flickr_url</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>427</td>\n",
              "      <td>640</td>\n",
              "      <td>2013-11-20 02:07:55</td>\n",
              "      <td>http://farm8.staticflickr.com/7187/6967031859_...</td>\n",
              "      <td>262145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>000000262146.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>2013-11-19 23:07:16</td>\n",
              "      <td>http://farm6.staticflickr.com/5090/5341741494_...</td>\n",
              "      <td>262146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>000000524291.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>426</td>\n",
              "      <td>640</td>\n",
              "      <td>2013-11-18 09:59:07</td>\n",
              "      <td>http://farm2.staticflickr.com/1045/934293170_d...</td>\n",
              "      <td>524291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>000000262148.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>512</td>\n",
              "      <td>640</td>\n",
              "      <td>2013-11-20 05:50:03</td>\n",
              "      <td>http://farm5.staticflickr.com/4028/4549977479_...</td>\n",
              "      <td>262148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>000000393223.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>480</td>\n",
              "      <td>640</td>\n",
              "      <td>2013-11-21 20:08:57</td>\n",
              "      <td>http://farm1.staticflickr.com/28/45521803_c5cb...</td>\n",
              "      <td>393223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39f7aa41-3c19-46b5-b610-2d14f3b43bc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39f7aa41-3c19-46b5-b610-2d14f3b43bc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39f7aa41-3c19-46b5-b610-2d14f3b43bc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   license         file_name  \\\n",
              "0        2  000000262145.jpg   \n",
              "1        1  000000262146.jpg   \n",
              "2        3  000000524291.jpg   \n",
              "3        1  000000262148.jpg   \n",
              "4        3  000000393223.jpg   \n",
              "\n",
              "                                            coco_url  height  width  \\\n",
              "0  http://images.cocodataset.org/train2017/000000...     427    640   \n",
              "1  http://images.cocodataset.org/train2017/000000...     640    480   \n",
              "2  http://images.cocodataset.org/train2017/000000...     426    640   \n",
              "3  http://images.cocodataset.org/train2017/000000...     512    640   \n",
              "4  http://images.cocodataset.org/train2017/000000...     480    640   \n",
              "\n",
              "         date_captured                                         flickr_url  \\\n",
              "0  2013-11-20 02:07:55  http://farm8.staticflickr.com/7187/6967031859_...   \n",
              "1  2013-11-19 23:07:16  http://farm6.staticflickr.com/5090/5341741494_...   \n",
              "2  2013-11-18 09:59:07  http://farm2.staticflickr.com/1045/934293170_d...   \n",
              "3  2013-11-20 05:50:03  http://farm5.staticflickr.com/4028/4549977479_...   \n",
              "4  2013-11-21 20:08:57  http://farm1.staticflickr.com/28/45521803_c5cb...   \n",
              "\n",
              "       id  \n",
              "0  262145  \n",
              "1  262146  \n",
              "2  524291  \n",
              "3  262148  \n",
              "4  393223  "
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "coco_meta.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dapjEW6-qbNu"
      },
      "outputs": [],
      "source": [
        "# Drop duplictes\n",
        "\n",
        "#coco_meta = coco_meta.drop_duplicates(subset=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urJ-R2EdGsCN"
      },
      "outputs": [],
      "source": [
        "# Read json file captions_train2017.json into dictionary\n",
        "\n",
        "\n",
        "\n",
        "# Opening JSON file\n",
        "\n",
        "f = open(ROOT + 'annotations/captions_train2017.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdAwysRvmF5q"
      },
      "outputs": [],
      "source": [
        "# return JSON object as a dictionary\n",
        "\n",
        "data = json.load(f)\n",
        "\n",
        "# Closing file\n",
        "\n",
        "#f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZCe0lEkmGrI"
      },
      "outputs": [],
      "source": [
        "# Convert dictionary to dataframe and only take data['annotations] dict\n",
        "\n",
        "cap_data = pd.DataFrame(data['annotations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bCC51YUqrmIf",
        "outputId": "cf0c3d55-a5f6-4d62-d37b-5d2dbbb53f48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3072ebcb-7b74-4337-8968-9dbffcb08e62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>id</th>\n",
              "      <th>caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>203564</td>\n",
              "      <td>37</td>\n",
              "      <td>A bicycle replica with a clock as the front wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>322141</td>\n",
              "      <td>49</td>\n",
              "      <td>A room with blue walls and a white sink and door.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16977</td>\n",
              "      <td>89</td>\n",
              "      <td>A car that seems to be parked illegally behind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106140</td>\n",
              "      <td>98</td>\n",
              "      <td>A large passenger airplane flying through the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>106140</td>\n",
              "      <td>101</td>\n",
              "      <td>There is a GOL plane taking off in a partly cl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3072ebcb-7b74-4337-8968-9dbffcb08e62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3072ebcb-7b74-4337-8968-9dbffcb08e62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3072ebcb-7b74-4337-8968-9dbffcb08e62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   image_id   id                                            caption\n",
              "0    203564   37  A bicycle replica with a clock as the front wh...\n",
              "1    322141   49  A room with blue walls and a white sink and door.\n",
              "2     16977   89  A car that seems to be parked illegally behind...\n",
              "3    106140   98  A large passenger airplane flying through the ...\n",
              "4    106140  101  There is a GOL plane taking off in a partly cl..."
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cap_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZneYYtkmJRX"
      },
      "outputs": [],
      "source": [
        "Caption_df = pd.merge(coco_meta,cap_data, left_on = 'id', right_on = 'image_id', how = 'inner')\n",
        "\n",
        "Caption_df = Caption_df[['image_id', 'id_y', 'caption', 'file_name']]\n",
        "\n",
        "Caption_df.drop_duplicates(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOXDMPjBNYe3"
      },
      "outputs": [],
      "source": [
        "# Drop unwanted columns\n",
        "#\n",
        "#Caption_df = Caption_df.drop(columns=['license', 'coco_url','height','width','date_captured','flickr_url','license'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bFD1s8cRN6ya",
        "outputId": "a959d562-1d41-4a43-c02e-43dc1930b23c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e1ecf467-acda-4461-b58b-be8e25b09520\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>id_y</th>\n",
              "      <th>caption</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262145</td>\n",
              "      <td>694</td>\n",
              "      <td>People shopping in an open market for vegetables.</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>262145</td>\n",
              "      <td>1054</td>\n",
              "      <td>An open market full of people and piles of veg...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262145</td>\n",
              "      <td>1456</td>\n",
              "      <td>People are shopping at an open air produce mar...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>262145</td>\n",
              "      <td>5248</td>\n",
              "      <td>Large piles of carrots and potatoes at a crowd...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262145</td>\n",
              "      <td>5254</td>\n",
              "      <td>People shop for vegetables like carrots and po...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40008</th>\n",
              "      <td>80067</td>\n",
              "      <td>782335</td>\n",
              "      <td>a dog that has a tooth brush in his mouth</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40009</th>\n",
              "      <td>80067</td>\n",
              "      <td>782578</td>\n",
              "      <td>Dog with a tooth brush in mouth in floor</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40010</th>\n",
              "      <td>80067</td>\n",
              "      <td>784051</td>\n",
              "      <td>Small gray and black dog holding a toothbrush ...</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40011</th>\n",
              "      <td>80067</td>\n",
              "      <td>784456</td>\n",
              "      <td>a close up o a dog with a tooth brush in its m...</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40012</th>\n",
              "      <td>80067</td>\n",
              "      <td>788209</td>\n",
              "      <td>A dog with a tooth brush in his mouth.</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25154 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ecf467-acda-4461-b58b-be8e25b09520')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1ecf467-acda-4461-b58b-be8e25b09520 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1ecf467-acda-4461-b58b-be8e25b09520');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       image_id    id_y                                            caption  \\\n",
              "0        262145     694  People shopping in an open market for vegetables.   \n",
              "1        262145    1054  An open market full of people and piles of veg...   \n",
              "2        262145    1456  People are shopping at an open air produce mar...   \n",
              "3        262145    5248  Large piles of carrots and potatoes at a crowd...   \n",
              "4        262145    5254  People shop for vegetables like carrots and po...   \n",
              "...         ...     ...                                                ...   \n",
              "40008     80067  782335          a dog that has a tooth brush in his mouth   \n",
              "40009     80067  782578           Dog with a tooth brush in mouth in floor   \n",
              "40010     80067  784051  Small gray and black dog holding a toothbrush ...   \n",
              "40011     80067  784456  a close up o a dog with a tooth brush in its m...   \n",
              "40012     80067  788209             A dog with a tooth brush in his mouth.   \n",
              "\n",
              "              file_name  \n",
              "0      000000262145.jpg  \n",
              "1      000000262145.jpg  \n",
              "2      000000262145.jpg  \n",
              "3      000000262145.jpg  \n",
              "4      000000262145.jpg  \n",
              "...                 ...  \n",
              "40008  000000080067.jpg  \n",
              "40009  000000080067.jpg  \n",
              "40010  000000080067.jpg  \n",
              "40011  000000080067.jpg  \n",
              "40012  000000080067.jpg  \n",
              "\n",
              "[25154 rows x 4 columns]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Caption_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKKtP3LyGsCO"
      },
      "source": [
        "### 2.2 Clean the captions\n",
        "\n",
        "Create a cleaned version of each caption. If using dataframes, we suggest saving the cleaned captions in a new column; otherwise, if you are storing your data in some other way, create data structures as needed. \n",
        "\n",
        "**A cleaned caption should be all lowercase, and consist of only alphabet characters.**\n",
        "\n",
        "Print out 10 original captions next to their cleaned versions to facilitate marking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dTuiB2Fdyb4p",
        "outputId": "b76d43fb-bef7-4e2e-967d-935f6005a664"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a87cc8e4-d9b1-40ba-9ca6-c216451ec9e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>id_y</th>\n",
              "      <th>caption</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262145</td>\n",
              "      <td>694</td>\n",
              "      <td>People shopping in an open market for vegetables.</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>262145</td>\n",
              "      <td>1054</td>\n",
              "      <td>An open market full of people and piles of veg...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262145</td>\n",
              "      <td>1456</td>\n",
              "      <td>People are shopping at an open air produce mar...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>262145</td>\n",
              "      <td>5248</td>\n",
              "      <td>Large piles of carrots and potatoes at a crowd...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262145</td>\n",
              "      <td>5254</td>\n",
              "      <td>People shop for vegetables like carrots and po...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a87cc8e4-d9b1-40ba-9ca6-c216451ec9e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a87cc8e4-d9b1-40ba-9ca6-c216451ec9e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a87cc8e4-d9b1-40ba-9ca6-c216451ec9e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   image_id  id_y                                            caption  \\\n",
              "0    262145   694  People shopping in an open market for vegetables.   \n",
              "1    262145  1054  An open market full of people and piles of veg...   \n",
              "2    262145  1456  People are shopping at an open air produce mar...   \n",
              "3    262145  5248  Large piles of carrots and potatoes at a crowd...   \n",
              "4    262145  5254  People shop for vegetables like carrots and po...   \n",
              "\n",
              "          file_name  \n",
              "0  000000262145.jpg  \n",
              "1  000000262145.jpg  \n",
              "2  000000262145.jpg  \n",
              "3  000000262145.jpg  \n",
              "4  000000262145.jpg  "
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Caption_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9AnD7XB5w5_",
        "outputId": "5daf1bc1-ca66-4064-93a9-1bb230f26457"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "#clean captions and lower them\n",
        "Caption_df['cleaned_caption'] = \"\"\n",
        "\n",
        "for index, row in Caption_df.iterrows():\n",
        "\n",
        "  row_lower = row[\"caption\"].lower()\n",
        "\n",
        "  row_lower = re.sub('[^a-z]+', ' ', row_lower)\n",
        "\n",
        "  Caption_df['cleaned_caption'][index] = row_lower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "KUg8JBd-GsCP",
        "outputId": "0d36e826-77b3-4767-8626-73f269a92b84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-50d73404-1d41-4a7f-96c0-f4f8315a1a75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>id_y</th>\n",
              "      <th>caption</th>\n",
              "      <th>file_name</th>\n",
              "      <th>cleaned_caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262145</td>\n",
              "      <td>694</td>\n",
              "      <td>People shopping in an open market for vegetables.</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>people shopping in an open market for vegetables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>262145</td>\n",
              "      <td>1054</td>\n",
              "      <td>An open market full of people and piles of veg...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>an open market full of people and piles of veg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262145</td>\n",
              "      <td>1456</td>\n",
              "      <td>People are shopping at an open air produce mar...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>people are shopping at an open air produce mar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>262145</td>\n",
              "      <td>5248</td>\n",
              "      <td>Large piles of carrots and potatoes at a crowd...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>large piles of carrots and potatoes at a crowd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262145</td>\n",
              "      <td>5254</td>\n",
              "      <td>People shop for vegetables like carrots and po...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>people shop for vegetables like carrots and po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>262146</td>\n",
              "      <td>634780</td>\n",
              "      <td>a person skiing down a steep hill</td>\n",
              "      <td>000000262146.jpg</td>\n",
              "      <td>a person skiing down a steep hill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>262146</td>\n",
              "      <td>637393</td>\n",
              "      <td>A person skiing down a steep snowy hill.</td>\n",
              "      <td>000000262146.jpg</td>\n",
              "      <td>a person skiing down a steep snowy hill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>262146</td>\n",
              "      <td>640348</td>\n",
              "      <td>A person on snow skis going down a steep slope.</td>\n",
              "      <td>000000262146.jpg</td>\n",
              "      <td>a person on snow skis going down a steep slope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>262146</td>\n",
              "      <td>641836</td>\n",
              "      <td>A skier is skiing down a down hill slope.</td>\n",
              "      <td>000000262146.jpg</td>\n",
              "      <td>a skier is skiing down a down hill slope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>262146</td>\n",
              "      <td>649789</td>\n",
              "      <td>A skier is shown taking on a very steep slope.</td>\n",
              "      <td>000000262146.jpg</td>\n",
              "      <td>a skier is shown taking on a very steep slope</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50d73404-1d41-4a7f-96c0-f4f8315a1a75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50d73404-1d41-4a7f-96c0-f4f8315a1a75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50d73404-1d41-4a7f-96c0-f4f8315a1a75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    image_id    id_y                                            caption  \\\n",
              "0     262145     694  People shopping in an open market for vegetables.   \n",
              "1     262145    1054  An open market full of people and piles of veg...   \n",
              "2     262145    1456  People are shopping at an open air produce mar...   \n",
              "3     262145    5248  Large piles of carrots and potatoes at a crowd...   \n",
              "4     262145    5254  People shop for vegetables like carrots and po...   \n",
              "15    262146  634780                 a person skiing down a steep hill    \n",
              "16    262146  637393           A person skiing down a steep snowy hill.   \n",
              "17    262146  640348    A person on snow skis going down a steep slope.   \n",
              "18    262146  641836         A skier is skiing down a down hill slope.    \n",
              "19    262146  649789     A skier is shown taking on a very steep slope.   \n",
              "\n",
              "           file_name                                    cleaned_caption  \n",
              "0   000000262145.jpg  people shopping in an open market for vegetables   \n",
              "1   000000262145.jpg  an open market full of people and piles of veg...  \n",
              "2   000000262145.jpg  people are shopping at an open air produce mar...  \n",
              "3   000000262145.jpg  large piles of carrots and potatoes at a crowd...  \n",
              "4   000000262145.jpg  people shop for vegetables like carrots and po...  \n",
              "15  000000262146.jpg                 a person skiing down a steep hill   \n",
              "16  000000262146.jpg           a person skiing down a steep snowy hill   \n",
              "17  000000262146.jpg    a person on snow skis going down a steep slope   \n",
              "18  000000262146.jpg          a skier is skiing down a down hill slope   \n",
              "19  000000262146.jpg     a skier is shown taking on a very steep slope   "
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Caption_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAaCB_M-M_59",
        "outputId": "ba013f4d-192e-4ebb-bcee-eb244e0bfc22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25154, 5)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Caption_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln4o4iFYK2hF"
      },
      "outputs": [],
      "source": [
        "Caption_df.to_csv(ROOT+\"cleaned_captions.csv\", encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bP01qMWGsCR"
      },
      "source": [
        "### 2.3  Split the data\n",
        "\n",
        "Split the data 70/10/20% into train/validation/test sets. **Be sure that each unique image (and all corresponding captions) only appear in a single set.**\n",
        "\n",
        "We provide the function below which, given a list of unique image IDs and a 3-split ratio, shuffles and returns  a split of the image IDs.\n",
        "\n",
        "If using a dataframe, ```df['image_id'].unique()``` will return the list of unique image IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uDvIg4XzGsCT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "def split_ids(image_id_list, train=.7, valid=0.1, test=0.2):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image_id_list (int list): list of unique image ids\n",
        "        train (float): train split size (between 0 - 1)\n",
        "        valid (float): valid split size (between 0 - 1)\n",
        "        test (float): test split size (between 0 - 1)\n",
        "    \"\"\"\n",
        "    #list_copy = image_id_list.copy()\n",
        "\n",
        "    list_copy = caption_df['image_id'].unique().copy()\n",
        "    random.shuffle(list_copy)\n",
        "    \n",
        "    train_size = math.floor(len(list_copy) * train)\n",
        "    valid_size = math.floor(len(list_copy) * valid)\n",
        "    \n",
        "    return list_copy[:train_size], list_copy[train_size:(train_size + valid_size)], list_copy[(train_size + valid_size):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "4ZXQX1URL3Wn",
        "outputId": "f83f5232-7a45-48c4-944f-936abdd17514"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       image_id    id_y                                            caption  \\\n",
              "0        262145     694  People shopping in an open market for vegetables.   \n",
              "1        262145    1054  An open market full of people and piles of veg...   \n",
              "2        262145    1456  People are shopping at an open air produce mar...   \n",
              "3        262145    5248  Large piles of carrots and potatoes at a crowd...   \n",
              "4        262145    5254  People shop for vegetables like carrots and po...   \n",
              "...         ...     ...                                                ...   \n",
              "25149     80067  782335          a dog that has a tooth brush in his mouth   \n",
              "25150     80067  782578           Dog with a tooth brush in mouth in floor   \n",
              "25151     80067  784051  Small gray and black dog holding a toothbrush ...   \n",
              "25152     80067  784456  a close up o a dog with a tooth brush in its m...   \n",
              "25153     80067  788209             A dog with a tooth brush in his mouth.   \n",
              "\n",
              "              file_name                                    cleaned_caption  \n",
              "0      000000262145.jpg  people shopping in an open market for vegetables   \n",
              "1      000000262145.jpg  an open market full of people and piles of veg...  \n",
              "2      000000262145.jpg  people are shopping at an open air produce mar...  \n",
              "3      000000262145.jpg  large piles of carrots and potatoes at a crowd...  \n",
              "4      000000262145.jpg  people shop for vegetables like carrots and po...  \n",
              "...                 ...                                                ...  \n",
              "25149  000000080067.jpg          a dog that has a tooth brush in his mouth  \n",
              "25150  000000080067.jpg           dog with a tooth brush in mouth in floor  \n",
              "25151  000000080067.jpg  small gray and black dog holding a toothbrush ...  \n",
              "25152  000000080067.jpg  a close up o a dog with a tooth brush in its m...  \n",
              "25153  000000080067.jpg             a dog with a tooth brush in his mouth   \n",
              "\n",
              "[25154 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55fe2b5d-ac81-422e-afec-2d3e3fa32b66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>id_y</th>\n",
              "      <th>caption</th>\n",
              "      <th>file_name</th>\n",
              "      <th>cleaned_caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>262145</td>\n",
              "      <td>694</td>\n",
              "      <td>People shopping in an open market for vegetables.</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>people shopping in an open market for vegetables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>262145</td>\n",
              "      <td>1054</td>\n",
              "      <td>An open market full of people and piles of veg...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>an open market full of people and piles of veg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262145</td>\n",
              "      <td>1456</td>\n",
              "      <td>People are shopping at an open air produce mar...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>people are shopping at an open air produce mar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>262145</td>\n",
              "      <td>5248</td>\n",
              "      <td>Large piles of carrots and potatoes at a crowd...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>large piles of carrots and potatoes at a crowd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262145</td>\n",
              "      <td>5254</td>\n",
              "      <td>People shop for vegetables like carrots and po...</td>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>people shop for vegetables like carrots and po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25149</th>\n",
              "      <td>80067</td>\n",
              "      <td>782335</td>\n",
              "      <td>a dog that has a tooth brush in his mouth</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "      <td>a dog that has a tooth brush in his mouth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25150</th>\n",
              "      <td>80067</td>\n",
              "      <td>782578</td>\n",
              "      <td>Dog with a tooth brush in mouth in floor</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "      <td>dog with a tooth brush in mouth in floor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25151</th>\n",
              "      <td>80067</td>\n",
              "      <td>784051</td>\n",
              "      <td>Small gray and black dog holding a toothbrush ...</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "      <td>small gray and black dog holding a toothbrush ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25152</th>\n",
              "      <td>80067</td>\n",
              "      <td>784456</td>\n",
              "      <td>a close up o a dog with a tooth brush in its m...</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "      <td>a close up o a dog with a tooth brush in its m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25153</th>\n",
              "      <td>80067</td>\n",
              "      <td>788209</td>\n",
              "      <td>A dog with a tooth brush in his mouth.</td>\n",
              "      <td>000000080067.jpg</td>\n",
              "      <td>a dog with a tooth brush in his mouth</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25154 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55fe2b5d-ac81-422e-afec-2d3e3fa32b66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55fe2b5d-ac81-422e-afec-2d3e3fa32b66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55fe2b5d-ac81-422e-afec-2d3e3fa32b66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "caption_df = pd.read_csv(ROOT + 'cleaned_captions.csv') # remove unamed column\n",
        "\n",
        "caption_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUlnmRqqMY5U",
        "outputId": "333b12d0-3a90-4cd5-8116-bbc67e5d5acf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['image_id', 'id_y', 'caption', 'file_name', 'cleaned_caption'], dtype='object')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "caption_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "V6RXfmGiGsCV"
      },
      "outputs": [],
      "source": [
        "train_set, valid_set, test_set = split_ids(caption_df['image_id'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "QbhNgditIEz9"
      },
      "outputs": [],
      "source": [
        "train_df = caption_df[caption_df['image_id'].isin(train_set)].reset_index()\n",
        "valid_df = caption_df[caption_df['image_id'].isin(valid_set)].reset_index()\n",
        "test_df = caption_df[caption_df['image_id'].isin(test_set)].reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUTizMF8GsCW"
      },
      "source": [
        "### 2.3 Building the vocabulary\n",
        "\n",
        "The vocabulary consists of all the possible words which can be used - both as input into the model, and as output predictions, and we will build it using the cleaned words found in the reference captions from the training set. In the vocabulary each unique word is mapped to a unique integer (a Python ```dictionary``` object).\n",
        "\n",
        "A ```Vocabulary``` object is provided for you below to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "Z2TsUdteGsCY"
      },
      "outputs": [],
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\" Simple vocabulary wrapper which maps every unique word to an integer ID. \"\"\"\n",
        "    def __init__(self):\n",
        "        # intially, set both the IDs and words to dictionaries with special tokens\n",
        "        self.word2idx = {'<pad>': 0, '<unk>': 1, '<end>': 2}\n",
        "        self.idx2word = {0: '<pad>', 1: '<unk>', 2: '<end>'}\n",
        "        self.idx = 3\n",
        "\n",
        "    def add_word(self, word):\n",
        "        # if the word does not already exist in the dictionary, add it\n",
        "        if not word in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            # increment the ID for the next word\n",
        "            self.idx += 1\n",
        "\n",
        "    def __call__(self, word):\n",
        "        # if we try to access a word not in the dictionary, return the id for <unk>\n",
        "        if not word in self.word2idx:\n",
        "            return self.word2idx['<unk>']\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_CMSqrTGsCc"
      },
      "source": [
        "Collect all words from the cleaned captions in the **training and validation sets**, ignoring any words which appear 3 times or less; this should leave you with roughly 2200 words (plus or minus is fine). As the vocabulary size affects the embedding layer dimensions, it is better not to add the very infrequently used words to the vocabulary.\n",
        "\n",
        "Create an instance of the ```Vocabulary()``` object and add all your words to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "V3GYKEZcHfpB"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "all_vocab_list = []\n",
        "remove_freq_vocab = []\n",
        "\n",
        "for caption in train_df['cleaned_caption']:\n",
        "  cap_vocab_list= caption.split(' ')\n",
        "  all_vocab_list.extend(cap_vocab_list)\n",
        "\n",
        "for caption in valid_df['cleaned_caption']:\n",
        "  cap_vocab_list= caption.split(' ')\n",
        "  all_vocab_list.extend(cap_vocab_list)\n",
        "    \n",
        "\n",
        "dict_vocab = Counter(all_vocab_list)\n",
        "\n",
        "for key, value in dict_vocab.items():\n",
        "        if value >3:\n",
        "          remove_freq_vocab.append(key)\n",
        "\n",
        "remove_freq_vocab = set(remove_freq_vocab)\n",
        "vocab = Vocabulary()\n",
        "for word in remove_freq_vocab:\n",
        "  vocab.add_word(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Myn0guQLY4y",
        "outputId": "5939a3bb-43f2-4929-cbb6-18d75526655e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2400"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "len(remove_freq_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueSOPtDPQAY3",
        "outputId": "177e7c48-d9da-44fd-b27d-e590269ea53f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2403"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ],
      "source": [
        "vocab.idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyCtFic1GsCk"
      },
      "source": [
        "### 2.4 The Dataset and DataLoader\n",
        "\n",
        "Create a PyTorch ```Dataset``` class and a corresponding ```DataLoader``` for the inputs to the decoder. Create three sets: one each for training, validation, and test. Set ```shuffle=True``` for the training set DataLoader.\n",
        "\n",
        "The ```Dataset``` function ```__getitem__(self, index)``` should return three Tensors:\n",
        "\n",
        ">1. A Tensor of image features, dimension (1, 4096).\n",
        ">2. A Tensor of integer word ids representing the reference caption; use your ```Vocabulary``` object to convert each word in the caption to a word ID. Be sure to add the word ID for the ```<unk>``` token at the end of each caption, then fill in the the rest of the caption with the ```<pad>``` token so that each caption has uniform lenth (max sequence length) of **47**.\n",
        ">3. A Tensor of integers representing the true lengths of every caption in the batch (include the ```<end>``` token in the count).\n",
        "\n",
        "\n",
        "Note that as each unique image has five or more (say, ```n```) reference captions, each image feature will appear ```n``` times, once in each unique (feature, caption) pair."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_path = ROOT+ \"imgid_features_map.pt\"\n",
        "features = torch.load(results_path)\n",
        "\n",
        "#imgid_df = train_df['image_id'][0]\n",
        "#img_features = features[imgid_df]"
      ],
      "metadata": {
        "id": "pVdXyw4gkmaO"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df)"
      ],
      "metadata": {
        "id": "C9RRUm-44K44",
        "outputId": "83b3456c-8c70-49fe-d624-79298f2aa76e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17606"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#file_name.replace('.jpg','')\n",
        "\n",
        "imgid_df = valid_df['file_name'][0].replace('.jpg','')\n",
        "imgid_df"
      ],
      "metadata": {
        "id": "PhaZ73uAoECj",
        "outputId": "b067386b-5ed6-4a0e-f4b6-f5fda53e2a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'000000524291'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imgid_df = train_df['image_id'][0]\n",
        "img_features = features[imgid_df]"
      ],
      "metadata": {
        "id": "Dpn-fFfin16q"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_features"
      ],
      "metadata": {
        "id": "ggjK-ndRpYq4",
        "outputId": "8128f814-b960-4064-92ab-9c9f8db06949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5213, 0.9413, 1.1224,  ..., 0.4759, 0.2304, 0.2302], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "2RA_iA85GsCo"
      },
      "outputs": [],
      "source": [
        "class COCO_Subset(Dataset):\n",
        "    \"\"\" COCO subset custom dataset, compatible with torch.utils.data.DataLoader. \"\"\"\n",
        "    \n",
        "    def __init__(self, df, features, vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df: (dataframe or some other data structure/s you may prefer to use)\n",
        "            features: image features\n",
        "            vocab: vocabulary wrapper\n",
        "           \n",
        "        \"\"\"\n",
        "        \n",
        "        # TO COMPLETE\n",
        "        self.df = df\n",
        "        self.features = features\n",
        "        self.vocab = vocab\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        \"\"\" Returns one data tuple (feature [1, 2048], target caption of word IDs [1, 47], and integer true caption length) \"\"\" \n",
        "        #img_features_list = []\n",
        "        imgid_df = self.df['file_name'][index].replace('.jpg','')\n",
        "        img_features = self.features[imgid_df]\n",
        "\n",
        "        #img_features = torch.tensor(img_features)\n",
        "        #return img_features\n",
        "        #img_features_list.append(img_features)\n",
        "        #target_f = torch.tensor(img_features)\n",
        "        \n",
        "        # if imgid_df in features:\n",
        "        #   #img_features = self.features[imgid_df]\n",
        "        #   print(imgid_df)\n",
        "        # else:\n",
        "        #   print(\"not found\")\n",
        "        #return img_features\n",
        "      \n",
        "        #img_features = torch.tensor(img_features)\n",
        "        #print(imag_features\n",
        "        \n",
        "        #id = self.df[\"img_id\"].iloc[index]\n",
        "        caption = self.df[\"cleaned_caption\"].iloc[index]\n",
        "        tokens = caption.split()\n",
        "        caption = []\n",
        "#         # Build the Tensor version of the caption, with token words\n",
        "         #caption.append(vocab('<start>'))\n",
        "        caption.extend([vocab(token) for token in tokens])\n",
        "        \n",
        "        caption.append(vocab('<end>'))\n",
        "        \n",
        "        len_cap = len(caption)\n",
        "        len_cap_47  = 47 - len_cap\n",
        "        #len_cap = torch.tensor(len_cap)\n",
        "        #print(len_cap_47)\n",
        "        #print(\"before\",caption)\n",
        "        \n",
        "        caption.extend([self.vocab('<pad>') for i in range(len_cap_47)])\n",
        "        #print(\"after\", caption)\n",
        "        target = torch.tensor(caption)\n",
        "        #print(target.shape, len(imag_features), len_cap.shape)\n",
        "        \n",
        "        return img_features, target, len_cap\n",
        "        #return img_features\n",
        "        \n",
        "        #get features\n",
        "       \n",
        "\n",
        "        # split caption into tokens.\n",
        "        #vocabs = self.df[index]\n",
        "        #return vocabs\n",
        "        #vocabs = self.df[index].split()\n",
        "#         caption = []\n",
        "#         # build the Tensor version of the caption, with token words\n",
        "#         caption.extend([self.vocab(v) for v in vocabs])\n",
        "#         caption.append(self.vocab('<end>'))\n",
        "        \n",
        "#         len_cap = len(caption)\n",
        "#         len_cap_47  = len_cap - 47\n",
        "#         len_cap = torch.Tensor(len_cap)\n",
        "        \n",
        "        \n",
        "#         caption.extend([self.vocab('<pad>') for i in range(len_cap_47)])\n",
        "#         target_cap = torch.Tensor(caption)\n",
        "#         return imag_features, target_cap , len_cap\n",
        "        \n",
        "       # TO COMPLETE\n",
        "    \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "JoBPq7qQGsCp"
      },
      "outputs": [],
      "source": [
        "#dataloader to get df for training, validation, test sets so change the following code to seprate them \n",
        "# I should use img_id in each set \n",
        "\n",
        "#df = train_df['cleaned_caption']\n",
        "\n",
        "results_path = ROOT+ \"imgid_features_map.pt\"\n",
        "features = torch.load(results_path)\n",
        "\n",
        "train_dataset = COCO_Subset(\n",
        "    df = train_df,\n",
        "    features = features,\n",
        "    vocab = vocab\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D__jdkJhGsCr"
      },
      "source": [
        "Load one batch of the training set and print out the shape of each returned Tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVPNBqLcGsCs",
        "outputId": "27adabfc-896a-4a5c-9e96-696fee119ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 47])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "train_iter = iter(train_loader)\n",
        "\n",
        "features, captions, lengths = train_iter.next()\n",
        "\n",
        "\n",
        "print(features.shape)\n",
        "print(captions.shape)\n",
        "print(lengths.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "zRMkBzvyteNs"
      },
      "outputs": [],
      "source": [
        "#dataloader to get df for training, validation, test sets so change the following code to seprate them \n",
        "# I should use img_id in each set \n",
        "# results_path = ROOT+ \"features.pt\"\n",
        "# features = torch.load(results_path)\n",
        "#df = train_df['cleaned_caption']\n",
        "\n",
        "results_path = ROOT+ \"imgid_features_map.pt\"\n",
        "features = torch.load(results_path)\n",
        "\n",
        "valid_dataset = COCO_Subset(\n",
        "    df = valid_df,\n",
        "    features = features,\n",
        "    vocab = vocab\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlahT7h6teNu",
        "outputId": "6082d309-db61-4beb-9a61-9dc2cac722a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 47])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "valid_iter = iter(valid_loader)\n",
        "features, captions, lengths = valid_iter.next()\n",
        "\n",
        "\n",
        "print(features.shape)\n",
        "print(captions.shape)\n",
        "print(lengths.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "2UUiVFShteNv"
      },
      "outputs": [],
      "source": [
        "#dataloader to get df for training, validation, test sets so change the following code to seprate them \n",
        "# I should use img_id in each set \n",
        "results_path = ROOT+ \"imgid_features_map.pt\"\n",
        "features = torch.load(results_path)\n",
        "#df = train_df['cleaned_caption']\n",
        "\n",
        "\n",
        "test_dataset = COCO_Subset(\n",
        "    df = test_df,\n",
        "    features = features,\n",
        "    vocab = vocab\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlE3IOJhteNv",
        "outputId": "814020e6-b6ae-480f-8511-eb2e479b6555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 47])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "test_iter = iter(test_loader)\n",
        "features, captions, lengths = test_iter.next()\n",
        "\n",
        "\n",
        "print(features.shape)\n",
        "print(captions.shape)\n",
        "print(lengths.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWtNIvp-GsCt"
      },
      "source": [
        "## 3 Train DecoderRNN [15 marks]\n",
        "\n",
        "### 3.1 Define the encoder model\n",
        "\n",
        "Read through the ```DecoderRNN``` model below. First, complete the decoder by adding an ```rnn``` layer to the decoder where indicated, using [the PyTorch API as reference](https://pytorch.org/docs/stable/nn.html#rnn).\n",
        "\n",
        "Keep all the default parameters except for ```batch_first```, which you may set to True.\n",
        "\n",
        "In particular, understand the meaning of ```pack_padded_sequence()``` as used in ```forward()```. Refer to the [PyTorch ```pack_padded_sequence()``` documentation](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "I0D7OoydGsCu"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=256, hidden_size=512, num_layers=1, max_seq_length=47):\n",
        "        \"\"\"Set the hyper-parameters and build the layers.\"\"\"\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        # we want a specific output size, which is the size of our embedding, so\n",
        "        # we feed our extracted features from the last fc layer (dimensions 1 x 2048)\n",
        "        # into a Linear layer to resize\n",
        "        self.resize = nn.Linear(2048, embed_size)\n",
        "        \n",
        "        # batch normalisation helps to speed up training\n",
        "        self.bn = nn.BatchNorm1d(embed_size, momentum=0.01)\n",
        "\n",
        "        # What is an embedding layer?\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        # TO COMPLETE\n",
        "        # self.rnn = \n",
        "        #Applies a multi-layer Elman RNN with tanh  or ReLU  non-linearity to an input sequence.\n",
        "        self.rnn = nn.RNN(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        \n",
        "\n",
        "    def forward(self, features, captions, lengths):\n",
        "        \"\"\"Decode image feature vectors and generates captions.\"\"\"\n",
        "        embeddings = self.embed(captions)\n",
        "        im_features = self.resize(features)\n",
        "        im_features = self.bn(im_features)\n",
        "        \n",
        "        embeddings = torch.cat((im_features.unsqueeze(1), embeddings), 1)\n",
        "    \n",
        "        packed = pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False) \n",
        "        # pack_padded_sequence returns a PackedSequence object, which contains two items: \n",
        "        # the packed data (data cut off at its true length and flattened into one list), and \n",
        "        # the batch_sizes, or the number of elements at each sequence step in the batch.\n",
        "        # For instance, given data [a, b, c] and [x] the PackedSequence would contain data \n",
        "        # [a, x, b, c] with batch_sizes=[2,1,1].\n",
        "        \n",
        "        hiddens, _ = self.rnn(packed)\n",
        "        outputs = self.linear(hiddens.data) # hiddens[0]\n",
        "        return outputs\n",
        "    \n",
        "    \n",
        "    def sample(self, features, states=None):\n",
        "        \"\"\"Generate captions for given image features using greedy search.\"\"\"\n",
        "        sampled_ids = []\n",
        "\n",
        "        inputs = self.bn(self.resize(features)).unsqueeze(1)\n",
        "        for i in range(self.max_seq_length):\n",
        "            hiddens, states = self.rnn(inputs, states)  # hiddens: (batch_size, 1, hidden_size)\n",
        "            outputs = self.linear(hiddens.squeeze(1))   # outputs:  (batch_size, vocab_size)\n",
        "            _, predicted = outputs.max(1)               # predicted: (batch_size)\n",
        "            sampled_ids.append(predicted)\n",
        "            inputs = self.embed(predicted)              # inputs: (batch_size, embed_size)\n",
        "            inputs = inputs.unsqueeze(1)                # inputs: (batch_size, 1, embed_size)\n",
        "        sampled_ids = torch.stack(sampled_ids, 1)       # sampled_ids: (batch_size, max_seq_length)\n",
        "        return sampled_ids\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "Ktfs883ZGsCw"
      },
      "outputs": [],
      "source": [
        "# instantiate decoder\n",
        "decoder = DecoderRNN(len(vocab)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jPFb_FrGsCx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhFU42HNGsCz"
      },
      "source": [
        "### 3.2 Train the decoder\n",
        "\n",
        "Train the decoder by passing the features, reference captions, and targets to the decoder, then computing loss based on the outputs and the targets. Note that when passing the targets and model outputs to the loss function, the targets will also need to be formatted using ```pack_padded_sequence()```.\n",
        "\n",
        "We recommend a batch size of around 64 (though feel free to adjust as necessary for your hardware).\n",
        "\n",
        "**We strongly recommend saving a checkpoint of your trained model after training so you don't need to re-train multiple times.**\n",
        "\n",
        "Display a graph of training and validation loss over epochs to justify your stopping point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "4qM4J-Awd3Ld"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "C4VJmFC4d38T"
      },
      "outputs": [],
      "source": [
        "# Define function to display training/validation loss/accuracy\n",
        "\n",
        "def display_trainingLossAcc(fileDir):\n",
        "\n",
        "  results_path = ROOT + fileDir\n",
        "\n",
        "  data = torch.load(results_path)\n",
        "\n",
        "  statsrec = data[\"stats\"]\n",
        "\n",
        "\n",
        "\n",
        "  fig, ax1 = plt.subplots()\n",
        "\n",
        "  plt.plot(statsrec[0], 'r', label = 'training loss', )\n",
        "\n",
        "  plt.plot(statsrec[1], 'g', label = 'Validation loss' )\n",
        "\n",
        "  plt.legend(loc='lower right')\n",
        "\n",
        "  plt.xlabel('epoch')\n",
        "\n",
        "  plt.ylabel('loss')\n",
        "\n",
        "  plt.title('Training and validation loss')\n",
        "\n",
        "  #ax2=ax1.twinx()\n",
        "\n",
        "  #ax2.plot(statsrec[1], 'm', label = 'training accuracy')\n",
        "\n",
        "  #ax2.plot(statsrec[3], 'b', label = 'Validation accuracy')\n",
        "\n",
        "  #ax2.set_ylabel('accuracy')\n",
        "\n",
        "  #plt.legend(loc='upper right')\n",
        "\n",
        "  fig.savefig(\"roc1Batch.svg\")\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "juZVTcjaeDI_"
      },
      "outputs": [],
      "source": [
        "# Define status function\n",
        "\n",
        "def status(loader, net):\n",
        "\n",
        "  correct = 0\n",
        "\n",
        "  total = 0\n",
        "\n",
        "  running_loss = 0\n",
        "\n",
        "  n = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for data in loader:\n",
        "\n",
        "      features, captions, lengths = data\n",
        "\n",
        "  #edit for GPU\n",
        "\n",
        "      features = features.to(device)\n",
        "\n",
        "      captions = captions.to(device)\n",
        "\n",
        "      #lengths = lengths.to(device)\n",
        "\n",
        "      outputs = decoder(features, captions, lengths)\n",
        "\n",
        "      targets = pack_padded_sequence(captions, lengths, batch_first=True, enforce_sorted=False)[0]\n",
        "\n",
        "      # accumulate loss\n",
        "\n",
        "      running_loss += loss_fn(outputs, targets) #targets\n",
        "\n",
        "      n += 1\n",
        "\n",
        "  # # accumulate data for accuracy\n",
        "\n",
        "  # _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "  # total += captions.size(0)\n",
        "\n",
        "  # correct += (predicted == captions).sum().item()\n",
        "\n",
        "  return running_loss/n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd01WGnNGsC2",
        "outputId": "81d47c13-b3d6-4283-849d-c8746a4ccc66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], Training Loss: 1.0950, Validation Loss: 3.8235\n",
            "Epoch [1], Training Loss: 1.0241, Validation Loss: 3.8475\n",
            "Epoch [2], Training Loss: 0.9916, Validation Loss: 3.8727\n",
            "Epoch [3], Training Loss: 0.9662, Validation Loss: 3.9047\n",
            "Epoch [4], Training Loss: 0.9409, Validation Loss: 3.9252\n",
            "Epoch [5], Training Loss: 0.9161, Validation Loss: 3.9584\n",
            "Epoch [6], Training Loss: 0.8942, Validation Loss: 3.9826\n",
            "Epoch [7], Training Loss: 0.8758, Validation Loss: 4.0067\n",
            "Epoch [8], Training Loss: 0.8552, Validation Loss: 4.0297\n",
            "Epoch [9], Training Loss: 0.8350, Validation Loss: 4.0609\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "\n",
        "cal_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.Adam(decoder.parameters(), lr=0.009) # check if encoder params need to be sent as well?\n",
        "\n",
        "optimizer = torch.optim.Adam(decoder.parameters(), lr=0.0002)\n",
        "\n",
        "statsrec = np.zeros((2,epochs))\n",
        "\n",
        "decoder_results = 'decoder_results20epochs.pt'\n",
        "\n",
        "results_path = ROOT + decoder_results\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  running_loss = 0.0\n",
        "\n",
        "  n = 0\n",
        "\n",
        "  for features, captions, lengths in train_loader:\n",
        "  \n",
        "\n",
        "    features = features.to(device)\n",
        "\n",
        "    captions = captions.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for each batch, prepare the targets using this torch.nn.utils.rnn function\n",
        "\n",
        "\n",
        "\n",
        "#targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
        "\n",
        "\n",
        "\n",
        "    targets = pack_padded_sequence(captions, lengths, batch_first=True, enforce_sorted=False)[0]\n",
        "\n",
        "\n",
        "\n",
        "    #print targets\n",
        "\n",
        "\n",
        "\n",
        "    outputs = decoder(features, captions, lengths)\n",
        "\n",
        "\n",
        "\n",
        "    #print(outputs.type)\n",
        "\n",
        "\n",
        "\n",
        "    #print(targets.type)\n",
        "\n",
        "\n",
        "\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss+= loss.item()\n",
        "\n",
        "    n+=1\n",
        "\n",
        "\n",
        "\n",
        "  loss_train = running_loss/n\n",
        "\n",
        "  loss_valid = status(valid_loader, decoder)\n",
        "\n",
        "  statsrec[:,epoch] = (loss_train, loss_valid.cpu())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('Epoch [{}], Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, loss_train, loss_valid ))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# save model after training\n",
        "\n",
        "\n",
        "\n",
        "#decoder_pt = torch.save(decoder, \"decoder.pt\")\n",
        "\n",
        "\n",
        "\n",
        "# save network parameters, losses and accuracy\n",
        "\n",
        "torch.save({\"state_dict\": decoder.state_dict(), \"stats\": statsrec}, results_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "pB6MKRrWeXSW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a0565389-7505-4c2e-f5fd-dc83a762d6fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "display_trainingLossAcc('decoder_results20epochs.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDS0OeswGsC3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAaYX74HGsC4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXzlLbstCE7f"
      },
      "source": [
        "## 4 Generate predictions on test data [8 marks]\n",
        "\n",
        "Display 5 sample test images containing different objects, along with your model’s generated captions and all the reference captions for each.\n",
        "\n",
        "> Remember that everything **displayed** in the submitted notebook and .html file will be marked, so be sure to run all relevant cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJimn9SRKWi5"
      },
      "outputs": [],
      "source": [
        "def get_prediction():\n",
        "    features, captions, lengths = next(iter(test_loader))\n",
        "    features = features.to(device)\n",
        "    #plt.imshow(np.squeeze(orig_image))\n",
        "    #plt.title('Sample Image')\n",
        "    #plt.show()\n",
        "    #image = image.to(device)\n",
        "    #features = encoder(image).unsqueeze(1)\n",
        "    output = decoder.sample(features)    \n",
        "    #sentence = clean_sentence(output)\n",
        "    #sentence = output\n",
        "    sentence = decode_caption(output, vocab)\n",
        "    #print(output)\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYFOSrCJLeeA",
        "outputId": "d9a62b25-6da5-4646-dab7-b2517d004f8b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "sampled_ids = get_prediction()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nINCDNWAXZ_K",
        "outputId": "a1cfef66-eb4b-4715-f383-4b7a6b00f395"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' a small bird walking in a field',\n",
              " ' a woman poses on a cart hanging',\n",
              " ' a <unk> of shops being flown in the background',\n",
              " ' a small red train is parked on the bed',\n",
              " ' a <unk> car parked on display in the background',\n",
              " ' a fire hydrant is in urban setting',\n",
              " ' a green fire hydrant is getting on a red car',\n",
              " ' two men playing baseball players flown in the background',\n",
              " ' a young child grazing cattle flown in a park',\n",
              " ' a fire hydrant is holding holding carts',\n",
              " ' a small dog walking on the beach',\n",
              " ' pad are walking on the bed',\n",
              " ' a woman in a parking lot in the background',\n",
              " ' a young woman in a park and red frisbee',\n",
              " ' a fire hydrant is holding another looks at a small shops']"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DrwqIksPjFT",
        "outputId": "e93124be-0046-405f-edc7-a20509446770"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function Tensor.type>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_ids.type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOWDSnSqOdsm"
      },
      "outputs": [],
      "source": [
        "def decode_caption(sampled_ids, vocab):\n",
        "    \"\"\" \n",
        "    Args:\n",
        "    \n",
        "        sampled_ids (int list): list of word IDs from decoder\n",
        "        vocab (Vocabulary): vocab for conversion\n",
        "    Return:\n",
        "        predicted_caption (str): predicted string sentence\n",
        "    \"\"\"\n",
        "    \n",
        "    predicted_caption_list = []\n",
        "    \n",
        "\n",
        "    sampled_ids = sampled_ids.cpu()\n",
        "    \n",
        "\n",
        "    if(torch.is_tensor(sampled_ids)):\n",
        "        sampled_ids_list = sampled_ids.numpy().tolist()\n",
        "\n",
        "    for cap_word in sampled_ids_list:\n",
        "      predicted_caption = \"\"\n",
        "      for word_id in cap_word:\n",
        "        \n",
        "        word = vocab.idx2word[word_id]\n",
        "        #if word == '<start>':\n",
        "         #   continue\n",
        "        if word == '<end>':\n",
        "            break\n",
        "        predicted_caption = predicted_caption + \" \" + word\n",
        "      predicted_caption_list.append(predicted_caption)\n",
        "\n",
        "    return predicted_caption_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdcK9g2hOsvQ",
        "outputId": "122c0c80-5b74-4608-b332-92714f048fba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' a small bird walking in a field',\n",
              " ' a woman poses on a cart hanging',\n",
              " ' a <unk> of shops being flown in the background',\n",
              " ' a small red train is parked on the bed',\n",
              " ' a <unk> car parked on display in the background',\n",
              " ' a fire hydrant is in urban setting',\n",
              " ' a green fire hydrant is getting on a red car',\n",
              " ' two men playing baseball players flown in the background',\n",
              " ' a young child grazing cattle flown in a park',\n",
              " ' a fire hydrant is holding holding carts',\n",
              " ' a small dog walking on the beach',\n",
              " ' pad are walking on the bed',\n",
              " ' a woman in a parking lot in the background',\n",
              " ' a young woman in a park and red frisbee',\n",
              " ' a fire hydrant is holding another looks at a small shops']"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decode_caption(sampled_ids, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDHeIYP2GsC8",
        "outputId": "326a3086-fd62-4643-b118-8303a3511c3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions on test dataset using final model (model_122b)\n",
        "\n",
        "predicted_class = []\n",
        "\n",
        "for features, captions, lengths in test_loader:\n",
        "\n",
        "  #features, captions, lengths = data\n",
        "  features = features.to(device)\n",
        "  captions = captions.to(device)\n",
        "  #lengths = lengths.to(device)\n",
        "\n",
        "# Forward, backward, and update parameters\n",
        "\n",
        "  outputs = decoder(features, captions, lengths)\n",
        "\n",
        "# the predicted lables / classes\n",
        "\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "#add the predicted lables to the list\n",
        "\n",
        "  predicted_class.extend(predicted.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wykE41lQHa8H",
        "outputId": "28db8fff-51a1-49fc-91e1-a0a527eeb76a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 187,\n",
              " 90,\n",
              " 1022,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 760,\n",
              " 560,\n",
              " 2153,\n",
              " 205,\n",
              " 2249,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2153,\n",
              " 2153,\n",
              " 760,\n",
              " 1256,\n",
              " 2249,\n",
              " 1651,\n",
              " 1256,\n",
              " 2349,\n",
              " 2250,\n",
              " 2311,\n",
              " 963,\n",
              " 1587,\n",
              " 2311,\n",
              " 1387,\n",
              " 2311,\n",
              " 1306,\n",
              " 1587,\n",
              " 997,\n",
              " 1587,\n",
              " 2311,\n",
              " 2311,\n",
              " 2311,\n",
              " 2051,\n",
              " 582,\n",
              " 1543,\n",
              " 1890,\n",
              " 1044,\n",
              " 90,\n",
              " 2311,\n",
              " 90,\n",
              " 2019,\n",
              " 1792,\n",
              " 1387,\n",
              " 2311,\n",
              " 90,\n",
              " 2311,\n",
              " 1076,\n",
              " 90,\n",
              " 16,\n",
              " 1044,\n",
              " 771,\n",
              " 86,\n",
              " 64,\n",
              " 1044,\n",
              " 1776,\n",
              " 2311,\n",
              " 1044,\n",
              " 90,\n",
              " 90,\n",
              " 1587,\n",
              " 1472,\n",
              " 1587,\n",
              " 1972,\n",
              " 86,\n",
              " 1256,\n",
              " 1587,\n",
              " 1890,\n",
              " 16,\n",
              " 158,\n",
              " 16,\n",
              " 1387,\n",
              " 1742,\n",
              " 1890,\n",
              " 86,\n",
              " 1256,\n",
              " 90,\n",
              " 1256,\n",
              " 1587,\n",
              " 1684,\n",
              " 2,\n",
              " 1076,\n",
              " 2,\n",
              " 1472,\n",
              " 86,\n",
              " 162,\n",
              " 2311,\n",
              " 314,\n",
              " 963,\n",
              " 1890,\n",
              " 1826,\n",
              " 1972,\n",
              " 524,\n",
              " 90,\n",
              " 2,\n",
              " 86,\n",
              " 90,\n",
              " 86,\n",
              " 86,\n",
              " 1890,\n",
              " 2311,\n",
              " 86,\n",
              " 1318,\n",
              " 86,\n",
              " 1826,\n",
              " 806,\n",
              " 963,\n",
              " 2,\n",
              " 1256,\n",
              " 2,\n",
              " 1684,\n",
              " 56,\n",
              " 1306,\n",
              " 1972,\n",
              " 1786,\n",
              " 2,\n",
              " 717,\n",
              " 56,\n",
              " 1890,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 680,\n",
              " 56,\n",
              " 2,\n",
              " 1318,\n",
              " 2,\n",
              " 2,\n",
              " 1890,\n",
              " 717,\n",
              " 262,\n",
              " 56,\n",
              " 2,\n",
              " 90,\n",
              " 1000,\n",
              " 2,\n",
              " 90,\n",
              " 56,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1758,\n",
              " 2,\n",
              " 892,\n",
              " 1684,\n",
              " 2,\n",
              " 524,\n",
              " 1076,\n",
              " 1705,\n",
              " 2,\n",
              " 1044,\n",
              " 560,\n",
              " 855,\n",
              " 86,\n",
              " 2,\n",
              " 1076,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 1326,\n",
              " 156,\n",
              " 910,\n",
              " 2153,\n",
              " 2153,\n",
              " 1651,\n",
              " 1256,\n",
              " 2153,\n",
              " 1776,\n",
              " 1651,\n",
              " 2249,\n",
              " 2249,\n",
              " 2249,\n",
              " 745,\n",
              " 963,\n",
              " 1797,\n",
              " 903,\n",
              " 2311,\n",
              " 1306,\n",
              " 963,\n",
              " 1387,\n",
              " 1587,\n",
              " 672,\n",
              " 2349,\n",
              " 649,\n",
              " 1587,\n",
              " 1587,\n",
              " 1587,\n",
              " 90,\n",
              " 2219,\n",
              " 963,\n",
              " 1306,\n",
              " 1044,\n",
              " 1318,\n",
              " 2219,\n",
              " 90,\n",
              " 87,\n",
              " 163,\n",
              " 1306,\n",
              " 672,\n",
              " 1044,\n",
              " 90,\n",
              " 1044,\n",
              " 1,\n",
              " 1021,\n",
              " 1890,\n",
              " 90,\n",
              " 90,\n",
              " 1890,\n",
              " 771,\n",
              " 56,\n",
              " 90,\n",
              " 1776,\n",
              " 90,\n",
              " 336,\n",
              " 86,\n",
              " 94,\n",
              " 1587,\n",
              " 2,\n",
              " 1306,\n",
              " 771,\n",
              " 1143,\n",
              " 94,\n",
              " 1587,\n",
              " 1306,\n",
              " 963,\n",
              " 334,\n",
              " 1044,\n",
              " 1143,\n",
              " 2311,\n",
              " 90,\n",
              " 1387,\n",
              " 892,\n",
              " 1890,\n",
              " 90,\n",
              " 1306,\n",
              " 2311,\n",
              " 1306,\n",
              " 86,\n",
              " 90,\n",
              " 1387,\n",
              " 2,\n",
              " 90,\n",
              " 231,\n",
              " 1076,\n",
              " 1086,\n",
              " 90,\n",
              " 1041,\n",
              " 1684,\n",
              " 681,\n",
              " 90,\n",
              " 934,\n",
              " 90,\n",
              " 717,\n",
              " 1256,\n",
              " 90,\n",
              " 90,\n",
              " 1684,\n",
              " 90,\n",
              " 90,\n",
              " 418,\n",
              " 1785,\n",
              " 1785,\n",
              " 1826,\n",
              " 806,\n",
              " 56,\n",
              " 86,\n",
              " 1786,\n",
              " 963,\n",
              " 963,\n",
              " 1785,\n",
              " 90,\n",
              " 516,\n",
              " 1763,\n",
              " 1684,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 94,\n",
              " 56,\n",
              " 1318,\n",
              " 1890,\n",
              " 1785,\n",
              " 1785,\n",
              " 90,\n",
              " 262,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 892,\n",
              " 1333,\n",
              " 1318,\n",
              " 1,\n",
              " 2,\n",
              " 892,\n",
              " 90,\n",
              " 1972,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 56,\n",
              " 1684,\n",
              " 1890,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 86,\n",
              " 86,\n",
              " 2062,\n",
              " 1890,\n",
              " 262,\n",
              " 1472,\n",
              " 2,\n",
              " 2,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 187,\n",
              " 90,\n",
              " 1983,\n",
              " 2153,\n",
              " 760,\n",
              " 2153,\n",
              " 1797,\n",
              " 760,\n",
              " 1616,\n",
              " 1256,\n",
              " 2199,\n",
              " 1152,\n",
              " 2249,\n",
              " 2328,\n",
              " 2153,\n",
              " 2153,\n",
              " 1919,\n",
              " 2328,\n",
              " 1306,\n",
              " 1306,\n",
              " 1306,\n",
              " 1235,\n",
              " 2311,\n",
              " 2311,\n",
              " 1306,\n",
              " 1587,\n",
              " 2311,\n",
              " 2222,\n",
              " 2311,\n",
              " 1306,\n",
              " 1306,\n",
              " 2311,\n",
              " 2311,\n",
              " 2199,\n",
              " 2199,\n",
              " 90,\n",
              " 1143,\n",
              " 1044,\n",
              " 1044,\n",
              " 2391,\n",
              " 90,\n",
              " 1,\n",
              " 2324,\n",
              " 1134,\n",
              " 2391,\n",
              " 1318,\n",
              " 2311,\n",
              " 90,\n",
              " 1143,\n",
              " 2311,\n",
              " 1776,\n",
              " 1143,\n",
              " 90,\n",
              " 1044,\n",
              " 2311,\n",
              " 94,\n",
              " 1306,\n",
              " 2,\n",
              " 2311,\n",
              " 2311,\n",
              " 2311,\n",
              " 1044,\n",
              " 94,\n",
              " 1044,\n",
              " 1044,\n",
              " 1890,\n",
              " 16,\n",
              " 1044,\n",
              " 1044,\n",
              " 1044,\n",
              " 16,\n",
              " 1318,\n",
              " 1318,\n",
              " 1044,\n",
              " 1044,\n",
              " 2311,\n",
              " 1044,\n",
              " 16,\n",
              " 1318,\n",
              " 90,\n",
              " 1318,\n",
              " 1318,\n",
              " 86,\n",
              " 86,\n",
              " 90,\n",
              " 1318,\n",
              " 2311,\n",
              " 1890,\n",
              " 86,\n",
              " 90,\n",
              " 1044,\n",
              " 86,\n",
              " 90,\n",
              " 680,\n",
              " 1972,\n",
              " 587,\n",
              " 56,\n",
              " 94,\n",
              " 680,\n",
              " 1972,\n",
              " 1333,\n",
              " 90,\n",
              " 963,\n",
              " 1306,\n",
              " 1972,\n",
              " 1472,\n",
              " 2400,\n",
              " 1,\n",
              " 1318,\n",
              " 2,\n",
              " 2,\n",
              " 1587,\n",
              " 2,\n",
              " 1306,\n",
              " 56,\n",
              " 86,\n",
              " 1256,\n",
              " 2,\n",
              " 1318,\n",
              " 262,\n",
              " 90,\n",
              " 2,\n",
              " 1333,\n",
              " 2249,\n",
              " 1387,\n",
              " 1972,\n",
              " 86,\n",
              " 90,\n",
              " 90,\n",
              " 2,\n",
              " 1195,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1011,\n",
              " 2,\n",
              " 1890,\n",
              " 111,\n",
              " 587,\n",
              " 2,\n",
              " 2,\n",
              " 1044,\n",
              " 2,\n",
              " 86,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1256,\n",
              " 2241,\n",
              " 2400,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 90,\n",
              " 680,\n",
              " 2,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 1686,\n",
              " 90,\n",
              " 90,\n",
              " 1,\n",
              " 1616,\n",
              " 2153,\n",
              " 1,\n",
              " 1651,\n",
              " 760,\n",
              " 2153,\n",
              " 1256,\n",
              " 1256,\n",
              " 2249,\n",
              " 2153,\n",
              " 1627,\n",
              " 2153,\n",
              " 2153,\n",
              " 2249,\n",
              " 2311,\n",
              " 2324,\n",
              " 1587,\n",
              " 649,\n",
              " 1235,\n",
              " 1587,\n",
              " 1472,\n",
              " 1587,\n",
              " 2349,\n",
              " 1,\n",
              " 1260,\n",
              " 2219,\n",
              " 1587,\n",
              " 1587,\n",
              " 2349,\n",
              " 1044,\n",
              " 1,\n",
              " 1044,\n",
              " 909,\n",
              " 90,\n",
              " 2324,\n",
              " 30,\n",
              " 1044,\n",
              " 1776,\n",
              " 1044,\n",
              " 2311,\n",
              " 154,\n",
              " 1022,\n",
              " 1044,\n",
              " 1982,\n",
              " 1209,\n",
              " 1587,\n",
              " 86,\n",
              " 909,\n",
              " 1256,\n",
              " 90,\n",
              " 1,\n",
              " 1209,\n",
              " 1742,\n",
              " 2200,\n",
              " 582,\n",
              " 90,\n",
              " 2400,\n",
              " 1209,\n",
              " 1209,\n",
              " 1890,\n",
              " 182,\n",
              " 1684,\n",
              " 1086,\n",
              " 1890,\n",
              " 1,\n",
              " 1044,\n",
              " 643,\n",
              " 560,\n",
              " 1677,\n",
              " 1472,\n",
              " 347,\n",
              " 988,\n",
              " 1472,\n",
              " 16,\n",
              " 90,\n",
              " 1086,\n",
              " 1826,\n",
              " 1306,\n",
              " 892,\n",
              " 16,\n",
              " 90,\n",
              " 86,\n",
              " 2051,\n",
              " 86,\n",
              " 2081,\n",
              " 2,\n",
              " 892,\n",
              " 1076,\n",
              " 1318,\n",
              " 680,\n",
              " 94,\n",
              " 2,\n",
              " 1318,\n",
              " 1899,\n",
              " 1758,\n",
              " 1758,\n",
              " 2,\n",
              " 86,\n",
              " 1262,\n",
              " 90,\n",
              " 86,\n",
              " 1972,\n",
              " 884,\n",
              " 855,\n",
              " 2,\n",
              " 1333,\n",
              " 90,\n",
              " 111,\n",
              " 2,\n",
              " 90,\n",
              " 2,\n",
              " 1318,\n",
              " 717,\n",
              " 1663,\n",
              " 1041,\n",
              " 90,\n",
              " 347,\n",
              " 1086,\n",
              " 2,\n",
              " 892,\n",
              " 2,\n",
              " 1544,\n",
              " 2,\n",
              " 86,\n",
              " 1890,\n",
              " 2081,\n",
              " 56,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 347,\n",
              " 892,\n",
              " 1525,\n",
              " 330,\n",
              " 94,\n",
              " 2,\n",
              " 2081,\n",
              " 1709,\n",
              " 2,\n",
              " 855,\n",
              " 2,\n",
              " 2,\n",
              " 1333,\n",
              " 90,\n",
              " 2,\n",
              " 2,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 1686,\n",
              " 1306,\n",
              " 438,\n",
              " 1651,\n",
              " 760,\n",
              " 1256,\n",
              " 2153,\n",
              " 521,\n",
              " 2249,\n",
              " 560,\n",
              " 2153,\n",
              " 2153,\n",
              " 1651,\n",
              " 2153,\n",
              " 2249,\n",
              " 2153,\n",
              " 1,\n",
              " 1587,\n",
              " 1472,\n",
              " 2311,\n",
              " 1587,\n",
              " 2250,\n",
              " 1235,\n",
              " 2249,\n",
              " 1387,\n",
              " 1387,\n",
              " 1387,\n",
              " 1587,\n",
              " 1587,\n",
              " 1587,\n",
              " 2311,\n",
              " 1380,\n",
              " 909,\n",
              " 1044,\n",
              " 87,\n",
              " 1022,\n",
              " 2324,\n",
              " 1890,\n",
              " 582,\n",
              " 90,\n",
              " 1022,\n",
              " 1543,\n",
              " 1044,\n",
              " 1044,\n",
              " 90,\n",
              " 1543,\n",
              " 90,\n",
              " 90,\n",
              " 1076,\n",
              " 1587,\n",
              " 2400,\n",
              " 330,\n",
              " 1972,\n",
              " 2311,\n",
              " 1587,\n",
              " 2362,\n",
              " 1044,\n",
              " 1890,\n",
              " 86,\n",
              " 1587,\n",
              " 1044,\n",
              " 94,\n",
              " 1758,\n",
              " 90,\n",
              " 851,\n",
              " 1677,\n",
              " 16,\n",
              " 16,\n",
              " 2298,\n",
              " 158,\n",
              " 1472,\n",
              " 1076,\n",
              " 2081,\n",
              " 1684,\n",
              " 643,\n",
              " 1256,\n",
              " 418,\n",
              " 1243,\n",
              " 1890,\n",
              " 988,\n",
              " 1296,\n",
              " 90,\n",
              " 1044,\n",
              " 1684,\n",
              " 2311,\n",
              " 1076,\n",
              " 90,\n",
              " 2,\n",
              " 2,\n",
              " 44,\n",
              " 2,\n",
              " 892,\n",
              " 1306,\n",
              " 1826,\n",
              " 90,\n",
              " 2,\n",
              " 1815,\n",
              " 86,\n",
              " 2400,\n",
              " 2081,\n",
              " 90,\n",
              " 1890,\n",
              " 90,\n",
              " 86,\n",
              " 90,\n",
              " 86,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1044,\n",
              " 2,\n",
              " 1306,\n",
              " 717,\n",
              " 1890,\n",
              " 90,\n",
              " 1972,\n",
              " 1890,\n",
              " 1972,\n",
              " 94,\n",
              " 1684,\n",
              " 1890,\n",
              " 851,\n",
              " 1972,\n",
              " 86,\n",
              " 86,\n",
              " 86,\n",
              " 1318,\n",
              " 2,\n",
              " 1296,\n",
              " 1544,\n",
              " 996,\n",
              " 2,\n",
              " 717,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1972,\n",
              " 2,\n",
              " 1684,\n",
              " 1684,\n",
              " 94,\n",
              " 56,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 86,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1709,\n",
              " 90,\n",
              " 1890,\n",
              " 94,\n",
              " 1826,\n",
              " 2,\n",
              " 2,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 90,\n",
              " 1594,\n",
              " 521,\n",
              " 1651,\n",
              " 2249,\n",
              " 2153,\n",
              " 1,\n",
              " 2311,\n",
              " 205,\n",
              " 935,\n",
              " 2153,\n",
              " 2249,\n",
              " 2153,\n",
              " 760,\n",
              " 2249,\n",
              " 2153,\n",
              " 1797,\n",
              " 2311,\n",
              " 1587,\n",
              " 806,\n",
              " 2311,\n",
              " 1493,\n",
              " 1583,\n",
              " 1,\n",
              " 2356,\n",
              " 28,\n",
              " 1587,\n",
              " 2349,\n",
              " 1677,\n",
              " 1677,\n",
              " 90,\n",
              " 2311,\n",
              " 1044,\n",
              " 1890,\n",
              " 672,\n",
              " 1982,\n",
              " 1587,\n",
              " 1044,\n",
              " 86,\n",
              " 2028,\n",
              " 90,\n",
              " 90,\n",
              " 1387,\n",
              " 672,\n",
              " 672,\n",
              " 1776,\n",
              " 1776,\n",
              " 86,\n",
              " 1333,\n",
              " 892,\n",
              " 1256,\n",
              " 2224,\n",
              " 892,\n",
              " 1,\n",
              " 963,\n",
              " 1776,\n",
              " 1776,\n",
              " 1044,\n",
              " 892,\n",
              " 892,\n",
              " 1387,\n",
              " 767,\n",
              " 1972,\n",
              " 1044,\n",
              " 1,\n",
              " 2311,\n",
              " 1044,\n",
              " 963,\n",
              " 2051,\n",
              " 90,\n",
              " 16,\n",
              " 16,\n",
              " 892,\n",
              " 1776,\n",
              " 963,\n",
              " 16,\n",
              " 934,\n",
              " 516,\n",
              " 90,\n",
              " 963,\n",
              " 2311,\n",
              " 90,\n",
              " 851,\n",
              " 245,\n",
              " 314,\n",
              " 892,\n",
              " 892,\n",
              " 1041,\n",
              " 2250,\n",
              " 1044,\n",
              " 1890,\n",
              " 90,\n",
              " 90,\n",
              " 1826,\n",
              " 2,\n",
              " 1044,\n",
              " 963,\n",
              " 1333,\n",
              " 685,\n",
              " 1580,\n",
              " 1972,\n",
              " 1972,\n",
              " 1587,\n",
              " 1472,\n",
              " 1890,\n",
              " 2,\n",
              " 1972,\n",
              " 86,\n",
              " 2,\n",
              " 2,\n",
              " 1086,\n",
              " 1228,\n",
              " 1044,\n",
              " 418,\n",
              " 2245,\n",
              " 2,\n",
              " 2,\n",
              " 1076,\n",
              " 90,\n",
              " 1972,\n",
              " 1318,\n",
              " 2,\n",
              " 717,\n",
              " 90,\n",
              " 1256,\n",
              " 2,\n",
              " 2,\n",
              " 1076,\n",
              " 2,\n",
              " 2,\n",
              " 1890,\n",
              " 162,\n",
              " 90,\n",
              " 2,\n",
              " 2,\n",
              " 1179,\n",
              " 2,\n",
              " 1890,\n",
              " 2,\n",
              " ...]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZoY_p2kGsC-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVfEgbC4I_dE"
      },
      "source": [
        "## 5 Caption evaluation using BLEU score [10 marks]\n",
        "\n",
        "There are different methods for measuring the performance of image to text models. We will evaluate our model by measuring the text similarity between the generated caption and the reference captions, using two commonly used methods. Ther first method is known as *Bilingual Evaluation Understudy (BLEU)*.\n",
        "\n",
        "###  5.1 BLEU score\n",
        "\n",
        "\n",
        "One common way of comparing a generated text to a reference text is using BLEU. This article gives a good intuition to how the BLEU score is computed: https://machinelearningmastery.com/calculate-bleu-score-for-text-python/, and you may find an implementation online to use. One option is the NLTK implementation `nltk.translate.bleu_score` here: https://www.nltk.org/api/nltk.translate.bleu_score.html\n",
        "\n",
        "\n",
        "> **Tip:** BLEU scores can be weighted by ith-gram. Check that your scores make sense; and feel free to use a weighting that best matches the data. We will not be looking for specific score ranges; rather we will check that the scores are reasonable and meaningful given the captions.\n",
        "\n",
        "Write the code to evaluate the trained model on the complete test set and calculate the BLEU score using the predictions, compared against all five references captions. \n",
        "\n",
        "Display a histogram of the distribution of scores over the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xypfUN7y4CKI"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CExm8xspGsDA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KM-iKzrGsDA"
      },
      "source": [
        "### 5.2 BLEU score examples\n",
        "\n",
        "Find one sample with high BLEU score and one with a low score, and display the model's predicted sentences, the BLEU scores, and the 5 reference captions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0Sp-eqhGsDB"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfzweU4aGsDG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VQKNo384CKP"
      },
      "source": [
        "## 6 Caption evaluation using cosine similarity [12 marks]\n",
        "\n",
        "###  6.1 Cosine similarity\n",
        "\n",
        "The cosine similarity measures the cosine of the angle between two vectors in n-dimensional space. The smaller the angle, the greater the similarity.\n",
        "\n",
        "To use the cosine similarity to measure the similarity between the generated caption and the reference captions: \n",
        "\n",
        "* Find the embedding vector of each word in the caption \n",
        "* Compute the average vector for each caption \n",
        "* Compute the cosine similarity score between the average vector of the generated caption and average vector of each reference caption\n",
        "* Compute the average of these scores \n",
        "\n",
        "Calculate the cosine similarity using the model's predictions over the whole test set. \n",
        "\n",
        "Display a histogram of the distribution of scores over the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoE0vxcAGsDK"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-0fyrMPGsDN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5HsLuvWGsDN"
      },
      "source": [
        "#### 6.2 Cosine similarity examples \n",
        "\n",
        "Find one sample with high cosine similarity score and one with a low score, and display the model's predicted sentences, the cosine similarity scores, and the 5 reference captions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wNOAF8oGsDO"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrXjgxAEGsDP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDmwrp-w4CKR"
      },
      "source": [
        "## 7 Comparing BLEU and Cosine similarity [16 marks]\n",
        "\n",
        "### 7.1 Test set distribution of scores\n",
        "\n",
        "Compare the model’s performance on the test set evaluated using BLEU and cosine similarity and discuss some weaknesses and strengths of each method (explain in words, in a text box below). \n",
        "\n",
        "Please note, to compare the average test scores, you need to rescale the Cosine similarity scores [-1 to 1] to match the range of BLEU method [0.0 - 1.0]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2O8TZG74CKS"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qigb0A9F4CKV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ACgM2N2GsDR"
      },
      "source": [
        " ### 7.2 Analysis of individual examples\n",
        " \n",
        "Find and display one example where both methods give similar scores and another example where they do not and discuss. Include both scores, predicted captions, and reference captions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LN-j2iDGsDR"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pte1o-BOGsDS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSgQGD6GGsDS"
      },
      "source": [
        "### Overall quality [5 marks]\n",
        "\n",
        "See the top of the notebook for submission instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2upV6w_GGsDT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9KM-iKzrGsDA",
        "i5HsLuvWGsDN",
        "zSgQGD6GGsDS"
      ],
      "name": "COMP5623M_CW2v2.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}